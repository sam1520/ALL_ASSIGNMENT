{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c602657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680b883",
   "metadata": {},
   "source": [
    "Question 1 - display all the header tags from ‘en.wikipedia.org/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c4c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " 'h1 Welcome to Wikipedia',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 From today's featured list\",\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header_tags = [] # empty list\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "    \n",
    "# print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd115f",
   "metadata": {},
   "source": [
    "Question 2 - IMDB’s Top rated 100 movies’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39b45c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>1971</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>1921</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            movies_name year_of_release  IMDB_rating\n",
       "0              The Shawshank Redemption            1994          9.3\n",
       "1                         The Godfather            1972          9.2\n",
       "2                 The Godfather Part II            1974          9.0\n",
       "3                       The Dark Knight            2008          9.0\n",
       "4                          12 Angry Men            1957          9.0\n",
       "..                                  ...             ...          ...\n",
       "95                   North by Northwest            1959          8.3\n",
       "96                   A Clockwork Orange            1971          8.3\n",
       "97                               Snatch            2000          8.2\n",
       "98  Le fabuleux destin d'Amélie Poulain            2001          8.3\n",
       "99                              The Kid            1921          8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "page2 = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup2.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup2.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "for k in year:\n",
    "    a=k.text.replace('(','')\n",
    "    year_of_release.append(a.replace(')','')) \n",
    "\n",
    "\n",
    "      \n",
    "# IMDB Rating\n",
    "rating = soup2.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 movies on IMDB\n",
    "IMDB_top_100=pd.DataFrame({})\n",
    "IMDB_top_100['movies_name']=movies_name\n",
    "IMDB_top_100['year_of_release']=year_of_release\n",
    "IMDB_top_100['IMDB_rating']=IMDB_rating  \n",
    "IMDB_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5bc44",
   "metadata": {},
   "source": [
    "Question-3 IMDB’s Top rated 100 Indian movies’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5988e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>2007</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>1977</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>2004</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               movies_name year_of_release  IMDB_rating\n",
       "0          Rang De Basanti            2006          8.1\n",
       "1                 3 Idiots            2009          8.4\n",
       "2         Taare Zameen Par            2007          8.3\n",
       "3           Dil Chahta Hai            2001          8.1\n",
       "4   Swades: We, the People            2004          8.2\n",
       "..                     ...             ...          ...\n",
       "95             Wake Up Sid            2009          7.6\n",
       "96                Rangeela            1995          7.4\n",
       "97     Shatranj Ke Khilari            1977          7.5\n",
       "98      Pyaar Ka Punchnama            2011          7.6\n",
       "99           Ek Hasina Thi            2004          7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page3 = requests.get(url)\n",
    "\n",
    "# check the page content\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup3.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup3.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "\n",
    "for k in year:\n",
    "    a=k.text.replace('(','')\n",
    "    year_of_release.append(a.replace(')','')) \n",
    "    \n",
    "\n",
    "# IMDB Rating\n",
    "rating = soup3.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 India imdb movies\n",
    "indian_top_100=pd.DataFrame({})\n",
    "indian_top_100['movies_name']=movies_name\n",
    "indian_top_100['year_of_release']=year_of_release\n",
    "indian_top_100['IMDB_rating']=IMDB_rating\n",
    "indian_top_100    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809420a",
   "metadata": {},
   "source": [
    "Q4 - Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d341a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4 = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "\n",
    "# page content\n",
    "soup4=BeautifulSoup(page4.content)\n",
    "\n",
    "# scraping the name\n",
    "name = [] # creating empty list\n",
    "for i in soup4.find_all(\"div\",class_=\"presidentListing\"): \n",
    "    name.append(i.find(\"h3\").text.split(\"(\")[0])\n",
    "    \n",
    "# scraping term of office\n",
    "office = [] # creating the empty list\n",
    "    \n",
    "for i in soup4.find_all(\"div\",class_=\"presidentListing\"):\n",
    "     office.append(i.find_all(\"p\")[0].text.split(\":\")[1])\n",
    "        \n",
    "    \n",
    "data = list(zip(name,office))                                           #zipping data\n",
    "df = pd.DataFrame(data,columns=[\"Name\",\"Term of Office\"])                    #Creating Dataset    \n",
    "df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60e9a7",
   "metadata": {},
   "source": [
    "Q5- Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0727dd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>35</td>\n",
       "      <td>3,965</td>\n",
       "      <td>113               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>47</td>\n",
       "      <td>5,294</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>29</td>\n",
       "      <td>3,229</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>3,988</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>29</td>\n",
       "      <td>2,917</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>37</td>\n",
       "      <td>3,520</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>34</td>\n",
       "      <td>2,976</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>43</td>\n",
       "      <td>3,101</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      35  3,965   \n",
       "1         India      47  5,294   \n",
       "2   New Zealand      29  3,229   \n",
       "3       England      36  3,988   \n",
       "4      Pakistan      25  2,649   \n",
       "5  South Africa      29  2,917   \n",
       "6    Bangladesh      37  3,520   \n",
       "7     Sri Lanka      34  2,976   \n",
       "8   West Indies      43  3,101   \n",
       "9   Afghanistan      20  1,419   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              113               ...  \n",
       "1                                                113  \n",
       "2                                                111  \n",
       "3                                                111  \n",
       "4                                                106  \n",
       "5                                                101  \n",
       "6                                                 95  \n",
       "7                                                 88  \n",
       "8                                                 72  \n",
       "9                                                 71  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec8131",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b877ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player                     Team Rating\n",
       "0             Babar Azam  PAK                        887\n",
       "1  Rassie van der Dussen                       SA    777\n",
       "2            Imam-ul-Haq                      PAK    740\n",
       "3        Quinton de Kock                       SA    740\n",
       "4           Shubman Gill                      IND    733\n",
       "5           David Warner                      AUS    732\n",
       "6            Steve Smith                      AUS    714\n",
       "7            Virat Kohli                      IND    714\n",
       "8           Rohit Sharma                      IND    704\n",
       "9        Kane Williamson                       NZ    700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page6 = requests.get(url)\n",
    "# see content in page6\n",
    "soup6 = BeautifulSoup(page6.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup6.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Batsmen\n",
    "Batsmen=pd.DataFrame({})\n",
    "Batsmen['Player']=players[:10]\n",
    "Batsmen['Team']=team_name[:10]\n",
    "Batsmen['Rating']=rating[:10]\n",
    "Batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d81707",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6168cb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                     Team Rating\n",
       "0    Josh Hazlewood  AUS                        713\n",
       "1       Trent Boult                       NZ    708\n",
       "2    Mohammed Siraj                      IND    702\n",
       "3    Mitchell Starc                      AUS    702\n",
       "4       Rashid Khan                      AFG    659\n",
       "5   Shakib Al Hasan                      BAN    648\n",
       "6    Shaheen Afridi                      PAK    641\n",
       "7  Mujeeb Ur Rahman                      AFG    637\n",
       "8        Adam Zampa                      AUS    633\n",
       "9     Mohammad Nabi                      AFG    631"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page7 = requests.get(url)\n",
    "\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup7.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC bowlers\n",
    "bowlers=pd.DataFrame({})\n",
    "bowlers['Player']=players[:10]\n",
    "bowlers['Team']=team_name[:10]\n",
    "bowlers['Rating']=rating[:10]\n",
    "bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc124b67",
   "metadata": {},
   "source": [
    "Question 6 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0b7938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      21  3,603   \n",
       "1       England      28  3,342   \n",
       "2  South Africa      26  3,098   \n",
       "3         India      27  2,820   \n",
       "4   New Zealand      25  2,553   \n",
       "5   West Indies      27  2,535   \n",
       "6    Bangladesh      13    983   \n",
       "7      Thailand       8    572   \n",
       "8      Pakistan      27  1,678   \n",
       "9     Sri Lanka       8    353   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              172               ...  \n",
       "1                                                119  \n",
       "2                                                119  \n",
       "3                                                104  \n",
       "4                                                102  \n",
       "5                                                 94  \n",
       "6                                                 76  \n",
       "7                                                 72  \n",
       "8                                                 62  \n",
       "9                                                 44  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page8 = requests.get(url)\n",
    "#see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "#scrape team names\n",
    "womens_team = soup8.find_all(\"span\",class_='u-hide-phablet')\n",
    "womens_team_name = []\n",
    "for i in womens_team:\n",
    "    womens_team_name.append(i.text)\n",
    "womens_matches = [] #empty list\n",
    "womens_points = [] #empty list\n",
    "womens_ratings = [] #empty list\n",
    "womens_new_list = [] #empty list\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    womens_matches.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    womens_points.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    womens_ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    womens_new_list.append(i.text)\n",
    "for i in range(0,len(womens_new_list)-1,2):\n",
    "    womens_matches.append(womens_new_list[i]) # other teams matches\n",
    "    womens_points.append(womens_new_list[i+1]) # other teams points\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams number of matches and ratings\n",
    "    womens_ratings.append(i.text)\n",
    "# Make data frame of top 10 ICC teams\n",
    "womens_icc=pd.DataFrame({})\n",
    "womens_icc['Team_name']=womens_team_name[:10]\n",
    "womens_icc['Matches']=womens_matches[:10]\n",
    "womens_icc['Points']=womens_points[:10]\n",
    "womens_icc['Ratings']=womens_ratings[:10]\n",
    "womens_icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c2a20",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1ce5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player                     Team Rating\n",
       "0         Alyssa Healy  AUS                        762\n",
       "1          Beth Mooney                      AUS    754\n",
       "2      Laura Wolvaardt                       SA    732\n",
       "3       Natalie Sciver                      ENG    731\n",
       "4          Meg Lanning                      AUS    717\n",
       "5     Harmanpreet Kaur                      IND    716\n",
       "6      Smriti Mandhana                      IND    714\n",
       "7       Rachael Haynes                      AUS    680\n",
       "8  Chamari Athapaththu                       SL    655\n",
       "9    Amy Satterthwaite                       NZ    641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page9 = requests.get(url)\n",
    "# see content in page9\n",
    "soup9 = BeautifulSoup(page9.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup9.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 Women's ODI Batting Rankings\n",
    "top_players=pd.DataFrame({})\n",
    "top_players['Player']=players[:10]\n",
    "top_players['Team']=team_name[:10]\n",
    "top_players['Rating']=rating[:10]\n",
    "top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9ca2a",
   "metadata": {},
   "source": [
    "iii)Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee5c3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Rating\n",
       "0   Hayley Matthews  WI                        373\n",
       "1    Natalie Sciver                     ENG    371\n",
       "2      Ellyse Perry                     AUS    366\n",
       "3    Marizanne Kapp                      SA    349\n",
       "4       Amelia Kerr                      NZ    336\n",
       "5     Deepti Sharma                     IND    322\n",
       "6  Ashleigh Gardner                     AUS    292\n",
       "7     Jess Jonassen                     AUS    250\n",
       "8          Nida Dar                     PAK    232\n",
       "9    Jhulan Goswami                     IND    214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page10 = requests.get(url)\n",
    "\n",
    "# see content in page10\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup10.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Women's ODI All-Rounder Rankings\n",
    "all_rounder=pd.DataFrame({})\n",
    "all_rounder['Player']=players[:10]\n",
    "all_rounder['Team']=team_name[:10]\n",
    "all_rounder['Rating']=rating[:10]\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb2a2ba",
   "metadata": {},
   "source": [
    "Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world : i) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de565531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "page7 = requests.get(url)\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "\n",
    "# creaing empty lists \n",
    "time = []\n",
    "headline = []\n",
    "newsLink = []\n",
    "\n",
    "#Iterating over all the news\n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     headline.append(i.find(\"a\",class_=\"LatestNews-headline\").text)  \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     time.append(i.find(\"time\").text)   \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     newsLink.append(i.find(\"a\",class_=\"LatestNews-headline\").get(\"href\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf92f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBS says Pinterest can rally more than 25% on ...</td>\n",
       "      <td>15 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/ubs-says-pins-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeyCorp can rally nearly 70% as investors over...</td>\n",
       "      <td>30 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/keycorp-can-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Treasury yields rise as investors weigh bankin...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/us-treasury-yi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netanyahu survives no-confidence vote as prote...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/angry-protests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saudi National Bank chair resigns just days af...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/saudi-national...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lebanon wakes up in two times zones over gover...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/lebanon-in-two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russia stirs outrage with plan for tactical nu...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Club Med owner is bullish on China's reopening...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/chinas-fosun-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNBC Daily Open: SVB deposits and loans find a...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'The first bank crisis of the Twitter generati...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/the-first-bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Worried about your kids and A.I? Experts discu...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/worried-about-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Germany is changing its immigration rules to a...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/germany-to-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>First Citizens to buy large chunk of failed Si...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/first-citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fed's Kashkari says stress in banking sector b...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/fed-kashkari-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Europe stocks open higher as investors hope fo...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pfizer signs agreement with China on improving...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/pfizer-signs-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>China's debt-heavy local governments look for ...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/chinas-local-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'Sell into rallies': Morgan Stanley names the ...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/sell-into-rall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rivian shares keep hitting all-time lows. Here...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/rivn-where-wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Here's how to spot a good growth stock, accord...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/fund-manager-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cramer: Banking crisis is doing the Fed's work...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/cramer-banking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Twitter source code leaked online, court filin...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/twitter-source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Asia-Pacific markets trade mixed as banking se...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/asia-markets-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CNBC Daily Open: Deutsche Bank is not Credit S...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>More millennials are turning 40 — and they're ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/27/millennials-ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stock futures rise as Wall Street tries to bui...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/stock-futures-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NATO, world leaders condemn Russia's 'dangerou...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/nato-world-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3 red flags that prove it might be time to qui...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/when-it-might-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I went to my first Pilates class ever: 14 begi...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/pilates-exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bitcoin is poised to blow up Africa's $86 bill...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/03/26/bitcoin-is-poi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   UBS says Pinterest can rally more than 25% on ...    15 Min Ago   \n",
       "1   KeyCorp can rally nearly 70% as investors over...    30 Min Ago   \n",
       "2   Treasury yields rise as investors weigh bankin...   2 Hours Ago   \n",
       "3   Netanyahu survives no-confidence vote as prote...   2 Hours Ago   \n",
       "4   Saudi National Bank chair resigns just days af...   2 Hours Ago   \n",
       "5   Lebanon wakes up in two times zones over gover...   3 Hours Ago   \n",
       "6   Russia stirs outrage with plan for tactical nu...   4 Hours Ago   \n",
       "7   Club Med owner is bullish on China's reopening...   4 Hours Ago   \n",
       "8   CNBC Daily Open: SVB deposits and loans find a...   5 Hours Ago   \n",
       "9   'The first bank crisis of the Twitter generati...   5 Hours Ago   \n",
       "10  Worried about your kids and A.I? Experts discu...   5 Hours Ago   \n",
       "11  Germany is changing its immigration rules to a...   5 Hours Ago   \n",
       "12  First Citizens to buy large chunk of failed Si...   6 Hours Ago   \n",
       "13  Fed's Kashkari says stress in banking sector b...   6 Hours Ago   \n",
       "14  Europe stocks open higher as investors hope fo...   6 Hours Ago   \n",
       "15  Pfizer signs agreement with China on improving...   8 Hours Ago   \n",
       "16  China's debt-heavy local governments look for ...   9 Hours Ago   \n",
       "17  'Sell into rallies': Morgan Stanley names the ...  10 Hours Ago   \n",
       "18  Rivian shares keep hitting all-time lows. Here...  10 Hours Ago   \n",
       "19  Here's how to spot a good growth stock, accord...  10 Hours Ago   \n",
       "20  Cramer: Banking crisis is doing the Fed's work...  10 Hours Ago   \n",
       "21  Twitter source code leaked online, court filin...  11 Hours Ago   \n",
       "22  Asia-Pacific markets trade mixed as banking se...  11 Hours Ago   \n",
       "23  CNBC Daily Open: Deutsche Bank is not Credit S...  12 Hours Ago   \n",
       "24  More millennials are turning 40 — and they're ...  12 Hours Ago   \n",
       "25  Stock futures rise as Wall Street tries to bui...  13 Hours Ago   \n",
       "26  NATO, world leaders condemn Russia's 'dangerou...  17 Hours Ago   \n",
       "27  3 red flags that prove it might be time to qui...  21 Hours Ago   \n",
       "28  I went to my first Pilates class ever: 14 begi...  21 Hours Ago   \n",
       "29  Bitcoin is poised to blow up Africa's $86 bill...  21 Hours Ago   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/03/27/ubs-says-pins-...  \n",
       "1   https://www.cnbc.com/2023/03/27/keycorp-can-ra...  \n",
       "2   https://www.cnbc.com/2023/03/27/us-treasury-yi...  \n",
       "3   https://www.cnbc.com/2023/03/27/angry-protests...  \n",
       "4   https://www.cnbc.com/2023/03/27/saudi-national...  \n",
       "5   https://www.cnbc.com/2023/03/27/lebanon-in-two...  \n",
       "6   https://www.cnbc.com/2023/03/27/ukraine-war-li...  \n",
       "7   https://www.cnbc.com/2023/03/27/chinas-fosun-t...  \n",
       "8   https://www.cnbc.com/2023/03/27/stock-markets-...  \n",
       "9   https://www.cnbc.com/2023/03/27/the-first-bank...  \n",
       "10  https://www.cnbc.com/2023/03/27/worried-about-...  \n",
       "11  https://www.cnbc.com/2023/03/27/germany-to-cha...  \n",
       "12  https://www.cnbc.com/2023/03/27/first-citizens...  \n",
       "13  https://www.cnbc.com/2023/03/27/fed-kashkari-b...  \n",
       "14  https://www.cnbc.com/2023/03/27/european-marke...  \n",
       "15  https://www.cnbc.com/2023/03/27/pfizer-signs-a...  \n",
       "16  https://www.cnbc.com/2023/03/27/chinas-local-g...  \n",
       "17  https://www.cnbc.com/2023/03/27/sell-into-rall...  \n",
       "18  https://www.cnbc.com/2023/03/27/rivn-where-wal...  \n",
       "19  https://www.cnbc.com/2023/03/27/fund-manager-r...  \n",
       "20  https://www.cnbc.com/2023/03/26/cramer-banking...  \n",
       "21  https://www.cnbc.com/2023/03/26/twitter-source...  \n",
       "22  https://www.cnbc.com/2023/03/27/asia-markets-h...  \n",
       "23  https://www.cnbc.com/2023/03/27/stock-markets-...  \n",
       "24  https://www.cnbc.com/2023/03/27/millennials-ar...  \n",
       "25  https://www.cnbc.com/2023/03/26/stock-futures-...  \n",
       "26  https://www.cnbc.com/2023/03/26/nato-world-lea...  \n",
       "27  https://www.cnbc.com/2023/03/26/when-it-might-...  \n",
       "28  https://www.cnbc.com/2023/03/26/pilates-exerci...  \n",
       "29  https://www.cnbc.com/2023/03/26/bitcoin-is-poi...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Dataset\n",
    "data = list(zip(headline,time,newsLink))                                           #zipping data\n",
    "df = pd.DataFrame(data,columns=[\"Headline\",\"Time\",\"News Link\"])   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d1be1",
   "metadata": {},
   "source": [
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days. https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details : i) Paper Title ii) Authors iii) Published Date iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "626e5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "page8 = requests.get(url)\n",
    "# see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "\n",
    "# creating empty lists\n",
    "title = []\n",
    "author = []\n",
    "date = []\n",
    "link = []\n",
    "\n",
    "# scraping required data \n",
    "for i in soup8.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "                      \n",
    "for i in soup8.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "for i in soup8.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    date.append(i.text)\n",
    "    \n",
    "for i in soup8.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    link.append(i.get(\"href\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a79626",
   "metadata": {},
   "source": [
    "Q9- Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffetspecial’ : i) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a60908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a03733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0aab8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):\n",
    "    name.append(i.text)\n",
    "location=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "price = []\n",
    "cuisine = []\n",
    "for i in soup.find_all(\"span\", class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text.split('|')[0])\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-3\"):\n",
    "    rating.append(i.text)\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "images = []\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab3aa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(location), len(price), len(cuisine), len(rating), len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59a1245d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>IMAGES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>₹ 1,680 for 2 (approx)</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>₹ 1,700 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant Name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "3  Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "\n",
       "                                            Location                    Price  \\\n",
       "0                     Connaught Place, Central Delhi  ₹ 2,000 for 2 (approx)    \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi  ₹ 1,680 for 2 (approx)    \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...  ₹ 3,000 for 2 (approx)    \n",
       "3             Pacific Mall,Tagore Garden, West Delhi  ₹ 2,000 for 2 (approx)    \n",
       "4                 Gardens Galleria,Sector 38A, Noida  ₹ 1,700 for 2 (approx)    \n",
       "5               Hilton Garden Inn,Saket, South Delhi  ₹ 2,400 for 2 (approx)    \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi  ₹ 1,800 for 2 (approx)    \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad  ₹ 1,900 for 2 (approx)    \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon  ₹ 2,200 for 2 (approx)    \n",
       "\n",
       "                         Cuisine Rating  \\\n",
       "0          Chinese, North Indian    4.1   \n",
       "1   North Indian, Asian, Italian    3.9   \n",
       "2           Italian, Continental    4.3   \n",
       "3          Chinese, North Indian    3.9   \n",
       "4          North Indian, Chinese    3.9   \n",
       "5          North Indian, Italian    3.9   \n",
       "6                   North Indian    3.7   \n",
       "7                   North Indian    3.8   \n",
       "8          North Indian, Mughlai    4.3   \n",
       "\n",
       "                                              IMAGES  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "DineOut=pd.DataFrame({})\n",
    "DineOut['Restaurant Name']=name\n",
    "DineOut['Location']=location\n",
    "DineOut['Price']=price \n",
    "DineOut['Cuisine']=cuisine  \n",
    "DineOut['Rating']=rating  \n",
    "DineOut['IMAGES']=images\n",
    "DineOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcca00c",
   "metadata": {},
   "source": [
    "10) Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en i) Rank ii) Publication iii) h5-index iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59601391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [429]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdb3511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "# creating empty lists\n",
    "rank = []\n",
    "publication = []\n",
    "h5Index = []\n",
    "h5Median = []\n",
    "\n",
    "# scraping rank \n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "\n",
    "# scraping publication    \n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "    \n",
    "\n",
    "# scraping h5index    \n",
    "for i in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5Index.append(i.text)\n",
    "   \n",
    "# scraping h5median      \n",
    "for i in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5Median.append(i.text)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3f1c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5 Index</th>\n",
       "      <th>h5 Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rank, Publication, h5 Index, h5 Median]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "data = list(zip(rank,publication,h5Index,h5Median))\n",
    "df = pd.DataFrame(data,columns=[\"Rank\",\"Publication\",\"h5 Index\",\"h5 Median\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6427e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
